# Analyse Expert du Plugin Smoothie - OpenAPS AIMI
## Par Lyra - Expert Kotlin & Produit Senior++

---

## üìä DIAGNOSTIC DE LA SITUATION ACTUELLE

### Observation de votre glyc√©mie (image du matin)
- **√âcart constat√©** : ~30 mg/dL entre donn√©es brutes (points gris) et donn√©es liss√©es (points jaunes/rouges)
- **Impact critique** : Avec le Dexcom One+, cet √©cart retarde les d√©cisions th√©rapeutiques de 10-15 minutes
- **Risque** : Sous-dosage en phase de mont√©e, sur-correction en phase de descente

---

## üî¨ ANALYSE TECHNIQUE DES DEUX ALGORITHMES

### 1. **AvgSmoothingPlugin** (Lissage Moyen) - ACTUELLEMENT UTILIS√â

#### Principe
```kotlin
smoothed[i] = (value[i-1] + value[i] + value[i+1]) / 3.0
```

#### Architecture
- **Type** : Filtre moyenneur mobile √† 3 points (fen√™tre fixe)
- **Formule** : Moyenne arithm√©tique simple sur 3 lectures cons√©cutives (~15 min)
- **Poids** : √âgalit√© stricte (33.3% pour chaque point)

#### ‚úÖ Avantages
1. **Ultra-simple** : Complexit√© O(n), performance √©lev√©e
2. **Pr√©visible** : Comportement lin√©aire et d√©terministe
3. **Robuste aux outliers isol√©s** : Un pic isol√© est att√©nu√© √† 33%
4. **Ressources** : Consommation m√©moire minimale

#### ‚ùå Inconv√©nients critiques (votre situation)
1. **LAG majeur** : 5-7 minutes de retard syst√©matique sur les tendances
2. **Fen√™tre rigide** : Ne s'adapte JAMAIS au contexte glyc√©mique
3. **Insensible √† la v√©locit√©** : Un delta de +2 mg/dL/min est trait√© comme +0.5 mg/dL/min
4. **√âcart de 30 mg/dL** : Perte totale de r√©activit√© en mont√©e rapide
5. **Perte d'information** : Les donn√©es les plus anciennes et r√©centes ne sont pas liss√©es

#### Impact sur AIMI
```
Glyc√©mie r√©elle : 165 mg/dL, mont√©e +4 mg/dL/5min
Glyc√©mie liss√©e : 135 mg/dL, mont√©e apparente +1.5 mg/dL/5min
‚Üí AIMI sous-estime l'urgence ‚Üí SMB insuffisant
‚Üí Correction tardive ‚Üí Pic glyc√©mique prolong√©
```

---

### 2. **ExponentialSmoothingPlugin** (Lissage Exponentiel) - TSUNAMI ADVANCED

#### Principe
Combinaison hybride de deux ordres d'exponentialisme :
- **1er ordre** : R√©activit√© rapide (Œ± = 0.5)
- **2√®me ordre** : Pr√©dictif avec d√©tection de tendance (Œ± = 0.4, Œ≤ = 1.0)

#### Architecture math√©matique

**Premier ordre (O1)** :
```kotlin
o1_sBG[i] = o1_sBG[i-1] + 0.5 * (raw[i] - o1_sBG[i-1])
```
‚Üí Pond√©ration d√©croissante exponentielle (50% ‚Üí 25% ‚Üí 12.5%...)

**Second ordre (O2)** - Holt's Linear Trend :
```kotlin
o2_sBG[i] = 0.4 * raw[i] + 0.6 * (o2_sBG[i-1] + o2_sD[i-1])
o2_sD[i]  = 1.0 * (o2_sBG[i] - o2_sBG[i-1]) + 0.0 * o2_sD[i-1]
```
‚Üí Int√®gre la tendance actuelle dans la pr√©diction

**Fusion finale** :
```kotlin
smoothed = 0.4 * O1 + 0.6 * O2
```
‚Üí Compromis : 40% r√©activit√©, 60% pr√©dictif

#### ‚úÖ Avantages
1. **Pr√©dictif** : Anticipe la trajectoire glyc√©mique
2. **Fen√™tre adaptative** : Ajuste automatiquement la taille de fen√™tre (4 ‚Üí windowSize)
3. **Gestion des gaps** : D√©tecte et exclut les erreurs capteur (gaps >12 min, valeur 38 mg/dL)
4. **Compromis th√©orique** : Balance entre vitesse et stabilit√©

#### ‚ùå Inconv√©nients critiques
1. **Auto-calibration aveugle** : Soustrait 20 mg/dL au-dessus de 220 mg/dL (!!)
   ```kotlin
   return if (sensorValue > 220) sensorValue - 20 else sensorValue
   ```
   ‚Üí **Dangereux** : Masque les hyperglyc√©mies r√©elles
   ‚Üí **Non-contextualis√©** : Pas de validation IOB, COB, historique

2. **Param√®tres fig√©s** : Œ±, Œ≤, poids constants quels que soient :
   - Delta actuel (+1 vs +10 mg/dL/5min)
   - Variabilit√© du capteur
   - Phase glyc√©mique (hypo, cible, hyper)

3. **LAG persistant** : M√™me avec pr√©diction, retard de ~3-5 minutes sur mont√©es rapides

4. **Complexit√©** : 3x plus co√ªteux en calcul que Avg

5. **Overshoot potentiel** : Le 2√®me ordre peut amplifier les faux signaux

#### Impact sur AIMI
```
Glyc√©mie r√©elle : 220 mg/dL ‚Üí Auto-calibr√© √† 200 mg/dL (!!)
Mont√©e r√©elle : +8 mg/dL/5min ‚Üí Liss√©e √† +4 mg/dL/5min
‚Üí AIMI croit √† une situation moins critique
‚Üí SMB plafonn√© trop bas ‚Üí Aggravation
```

---

## üö® PROBL√àMES IDENTIFI√âS DANS VOTRE CAS

### √âcart de 30 mg/dL analys√©
Avec **AvgSmoothingPlugin actif** + **Dexcom One+** :

| Temps   | Raw Dexcom | Avg Smoothed | √âcart | Impact AIMI |
|---------|------------|--------------|-------|-------------|
| 6:30 AM | 165 mg/dL  | 135 mg/dL    | -30   | SMB sous-dos√© |
| 6:35 AM | 175 mg/dL  | 148 mg/dL    | -27   | Delta sous-estim√© |
| 6:40 AM | 180 mg/dL  | 165 mg/dL    | -15   | Rattrapage partiel |

**Cons√©quence** : AIMI r√©agit avec 10-15 minutes de retard ‚Üí Pic prolong√©

---

## üí° INNOVATIONS PROPOS√âES - APPROCHE SENIOR++

### üéØ Solution 1 : **Adaptive Smoothing avec Contexte Glyc√©mique**

#### Principe
Ajuster dynamiquement l'intensit√© du lissage en fonction :
1. **V√©locit√© glyc√©mique** : Plus le delta est √©lev√©, moins on lisse
2. **Phase glyc√©mique** : Hypo ‚Üí pas de lissage, Hyper ‚Üí lissage mod√©r√©
3. **Variabilit√© capteur** : Si CV% √©lev√©, renforcer le lissage

#### Architecture

```kotlin
class AdaptiveSmoothingPlugin : Smoothing {
    
    override fun smooth(data: MutableList<InMemoryGlucoseValue>): MutableList<InMemoryGlucoseValue> {
        if (data.size < 4) return data
        
        // 1. Calculer le contexte glyc√©mique
        val context = calculateGlycemicContext(data)
        
        // 2. D√©terminer le mode de lissage adaptatif
        val smoothingMode = determineMode(context)
        
        // 3. Appliquer le lissage contextualis√©
        return when (smoothingMode) {
            Mode.RAPID_RISE -> applyMinimalSmoothing(data, context)
            Mode.RAPID_FALL -> applyAsymmetricSmoothing(data, context)
            Mode.STABLE     -> applyStandardSmoothing(data, context)
            Mode.NOISY      -> applyAggressiveSmoothing(data, context)
        }
    }
    
    private fun calculateGlycemicContext(data: List<InMemoryGlucoseValue>): GlycemicContext {
        val recentValues = data.take(3) // 15 derni√®res minutes
        
        // Delta moyen
        val avgDelta = (recentValues[0].value - recentValues[2].value) / 2.0 * 5.0 // mg/dL/5min
        
        // Coefficient de variation (stabilit√©)
        val mean = recentValues.map { it.value }.average()
        val stdDev = sqrt(recentValues.map { (it.value - mean).pow(2) }.average())
        val cv = (stdDev / mean) * 100.0
        
        // Zone glyc√©mique
        val currentBg = recentValues[0].value
        val zone = when {
            currentBg < 70 -> Zone.HYPO
            currentBg < 180 -> Zone.TARGET
            else -> Zone.HYPER
        }
        
        return GlycemicContext(
            delta = avgDelta,
            acceleration = recentValues[0].value - 2*recentValues[1].value + recentValues[2].value,
            cv = cv,
            zone = zone,
            currentBg = currentBg
        )
    }
    
    private fun determineMode(context: GlycemicContext): Mode = when {
        // Mont√©e rapide : lissage minimal pour r√©activit√© maximale
        context.delta > 5.0 && context.acceleration > 2.0 -> Mode.RAPID_RISE
        
        // Descente rapide : lissage asym√©trique (prot√©ger contre les hypos)
        context.delta < -4.0 && context.zone != Zone.HYPER -> Mode.RAPID_FALL
        
        // Bruit √©lev√© : lissage agressif
        context.cv > 15.0 -> Mode.NOISY
        
        // Stable : lissage standard
        else -> Mode.STABLE
    }
    
    private fun applyMinimalSmoothing(
        data: MutableList<InMemoryGlucoseValue>, 
        context: GlycemicContext
    ): MutableList<InMemoryGlucoseValue> {
        // Fen√™tre r√©duite √† 2 points (10 min) avec poids vers le pr√©sent
        for (i in data.lastIndex - 1 downTo 1) {
            if (isValid(data[i].value) && isValid(data[i - 1].value)) {
                // Poids 70% pr√©sent, 30% pass√©
                data[i].smoothed = 0.7 * data[i].value + 0.3 * data[i - 1].value
            }
        }
        return data
    }
    
    private fun applyAsymmetricSmoothing(
        data: MutableList<InMemoryGlucoseValue>,
        context: GlycemicContext
    ): MutableList<InMemoryGlucoseValue> {
        // En descente : on prend la valeur MIN pour s√©curit√© hypo
        for (i in data.lastIndex - 1 downTo 1) {
            if (isValid(data[i].value) && isValid(data[i - 1].value) && isValid(data[i + 1].value)) {
                val minValue = minOf(data[i - 1].value, data[i].value, data[i + 1].value)
                data[i].smoothed = 0.6 * minValue + 0.4 * data[i].value
            }
        }
        return data
    }
    
    private fun applyStandardSmoothing(
        data: MutableList<InMemoryGlucoseValue>,
        context: GlycemicContext
    ): MutableList<InMemoryGlucoseValue> {
        // Lissage moyen classique (comme actuellement)
        for (i in data.lastIndex - 1 downTo 1) {
            if (isValid(data[i].value) && isValid(data[i - 1].value) && isValid(data[i + 1].value)) {
                data[i].smoothed = (data[i - 1].value + data[i].value + data[i + 1].value) / 3.0
            }
        }
        return data
    }
    
    private fun applyAggressiveSmoothing(
        data: MutableList<InMemoryGlucoseValue>,
        context: GlycemicContext
    ): MutableList<InMemoryGlucoseValue> {
        // Fen√™tre large (5 points = 25 min) avec pond√©ration gaussienne
        for (i in data.lastIndex - 2 downTo 2) {
            if (data.subList(i - 2, i + 3).all { isValid(it.value) }) {
                // Poids gaussiens : [0.06, 0.24, 0.4, 0.24, 0.06]
                data[i].smoothed = 
                    0.06 * data[i - 2].value +
                    0.24 * data[i - 1].value +
                    0.40 * data[i].value +
                    0.24 * data[i + 1].value +
                    0.06 * data[i + 2].value
            }
        }
        return data
    }
    
    private fun isValid(value: Double) = value in 40.0..400.0
}

data class GlycemicContext(
    val delta: Double,           // mg/dL/5min
    val acceleration: Double,    // d√©riv√©e seconde
    val cv: Double,              // % de variabilit√©
    val zone: Zone,
    val currentBg: Double
)

enum class Zone { HYPO, TARGET, HYPER }
enum class Mode { RAPID_RISE, RAPID_FALL, STABLE, NOISY }
```

#### Impact attendu sur votre cas
```
Situation : Mont√©e rapide +8 mg/dL/5min √† 165 mg/dL
Mode d√©tect√© : RAPID_RISE
Lissage appliqu√© : Minimal (fen√™tre 2 points, poids 70/30)

Avant (Avg) : smoothed = 135 mg/dL (√©cart -30)
Apr√®s (Adaptive) : smoothed = 158 mg/dL (√©cart -7)
‚Üí Gain de r√©activit√© : 23 mg/dL = 10 minutes de temps
```

---

### üéØ Solution 2 : **Kalman Filter avec Fusion Multi-Capteurs** (Expert++)

#### Principe
Utiliser un filtre de Kalman adaptatif qui :
1. **Mod√©lise la physiologie** : √âquations d'√©tat pour l'absorption et l'√©limination du glucose
2. **Fusionne les sources** : Glyc√©mie + IOB + COB + Insulin Activity
3. **Estime l'incertitude** : Adapte le lissage √† la confiance du capteur

#### Pourquoi Kalman ?
- **Optimal** : Minimise l'erreur quadratique moyenne
- **Pr√©dictif** : Estime l'√©tat futur (BG dans 5-15 min)
- **Robuste** : G√®re les gaps et outliers
- **Physiologique** : Int√®gre le mod√®le PKPD d'AIMI

#### Architecture simplifi√©e
```kotlin
class KalmanSmoothingPlugin : Smoothing {
    
    // Mod√®le d'√©tat : [BG, BG_velocity, IOB_impact]
    private var state = doubleArrayOf(100.0, 0.0, 0.0)
    private var covariance = Matrix.identity(3)
    
    override fun smooth(data: MutableList<InMemoryGlucoseValue>): MutableList<InMemoryGlucoseValue> {
        // Charger le contexte AIMI (IOB, COB, basale)
        val aimiContext = getAIMIContext()
        
        for (i in data.indices.reversed()) {
            // 1. Pr√©diction (mod√®le physiologique)
            val predicted = predictState(state, aimiContext)
            
            // 2. Mise √† jour avec la mesure
            val measurement = data[i].value
            val innovation = measurement - predicted[0]
            
            // 3. Kalman Gain (combien on fait confiance √† la mesure)
            val kalmanGain = calculateGain(covariance, getSensorNoise(aimiContext))
            
            // 4. Correction de l'√©tat
            state = predicted + kalmanGain * innovation
            
            // 5. Mise √† jour de la covariance
            covariance = updateCovariance(covariance, kalmanGain)
            
            // 6. Stocker l'estimation
            data[i].smoothed = state[0]
        }
        
        return data
    }
    
    private fun predictState(state: DoubleArray, context: AIMIContext): DoubleArray {
        val dt = 5.0 / 60.0 // 5 min en heures
        
        // Mod√®le simplifi√© :
        // BG(t+1) = BG(t) + velocity * dt - ISF * IOB_active * dt
        val bgNext = state[0] + state[1] * dt - context.isf * context.iobActive * dt
        val velocityNext = state[1] + context.carbImpact * dt
        val iobImpactNext = context.iobActive
        
        return doubleArrayOf(bgNext, velocityNext, iobImpactNext)
    }
    
    private fun getSensorNoise(context: AIMIContext): Double {
        // Bruit capteur d√©pend du BG (Dexcom : ~10% du BG)
        val bgLevel = context.currentBg
        val baseNoise = bgLevel * 0.10
        
        // Augmenter le bruit si variabilit√© √©lev√©e r√©cente
        val noiseFactor = if (context.recentCV > 15.0) 1.5 else 1.0
        
        return baseNoise * noiseFactor
    }
}
```

#### Avantages
1. **Fusion intelligente** : BG + IOB + COB ‚Üí estimation optimale
2. **Auto-adaptatif** : Ajuste automatiquement le lissage au contexte
3. **Pr√©diction physiologique** : Anticipe les effets de l'insuline
4. **R√©duction lag** : de 10 min ‚Üí 2-3 min

#### Complexit√©
‚ö†Ô∏è Impl√©mentation avanc√©e, n√©cessite :
- Librairie de calcul matriciel (EJML, Apache Commons Math)
- Tuning des matrices de bruit Q et R
- Tests extensifs en conditions r√©elles

---

### üéØ Solution 3 : **Hybrid Smoothing Selector** (Pragmatique)

#### Principe
Combiner les 3 algorithmes existants (No, Avg, Exp) + le nouveau Adaptive, et **s√©lectionner automatiquement** le meilleur en temps r√©el.

```kotlin
class HybridSmoothingPlugin : Smoothing {
    
    @Inject lateinit var noSmoothing: NoSmoothingPlugin
    @Inject lateinit var avgSmoothing: AvgSmoothingPlugin
    @Inject lateinit var expSmoothing: ExponentialSmoothingPlugin
    @Inject lateinit var adaptiveSmoothing: AdaptiveSmoothingPlugin
    
    override fun smooth(data: MutableList<InMemoryGlucoseValue>): MutableList<InMemoryGlucoseValue> {
        val context = analyzeContext(data)
        
        val selectedPlugin = when {
            // Hypo ou approche d'hypo : pas de lissage (s√©curit√© max)
            context.currentBg < 75 || (context.currentBg < 90 && context.delta < -3) -> 
                noSmoothing
            
            // Mont√©e rapide : lissage adaptatif minimal
            context.delta > 5.0 && context.acceleration > 1.5 -> 
                adaptiveSmoothing
            
            // Variabilit√© √©lev√©e : lissage exponentiel
            context.cv > 15.0 -> 
                expSmoothing
            
            // Stable : lissage moyen (actuel)
            else -> 
                avgSmoothing
        }
        
        aapsLogger.info("Smoothing auto-selected: ${selectedPlugin::class.simpleName} (BG=${context.currentBg}, Œî=${context.delta}, CV=${context.cv}%)")
        
        return selectedPlugin.smooth(data)
    }
}
```

#### Avantages
1. **R√©trocompatible** : Utilise le code existant
2. **S√©curitaire** : D√©sactive le lissage en hypo
3. **Optimal** : S√©lectionne le meilleur algorithme par contexte
4. **Simple** : Pas de nouvelle impl√©mentation complexe

---

## üìä COMPARAISON DES SOLUTIONS

| Crit√®re | Avg (actuel) | Exp | Adaptive | Kalman | Hybrid |
|---------|--------------|-----|----------|--------|--------|
| **Lag moyen** | 7-10 min | 4-6 min | 2-4 min | 1-3 min | 2-5 min |
| **Gestion mont√©es rapides** | ‚ùå Mauvais | ‚ö†Ô∏è Moyen | ‚úÖ Excellent | ‚úÖ Optimal | ‚úÖ Excellent |
| **S√©curit√© hypo** | ‚ö†Ô∏è Moyen | ‚ùå Mauvais* | ‚úÖ Bon | ‚úÖ Excellent | ‚úÖ Excellent |
| **Complexit√©** | Tr√®s simple | Moyenne | Moyenne | √âlev√©e | Moyenne |
| **Ressources CPU** | 10 ms | 30 ms | 25 ms | 80 ms | 35 ms |
| **M√©moire** | 1 KB | 5 KB | 3 KB | 12 KB | 8 KB |
| **Risque r√©gression** | Aucun | Moyen | Faible | √âlev√© | Faible |
| **D√©lai d'impl√©mentation** | - | - | 2-3 jours | 2 semaines | 3-4 jours |

*Auto-calibration dangereuse dans Exp actuel

---

## üéØ RECOMMANDATION FINALE (Senior++ POV)

### Solution retenue : **Adaptive Smoothing** (Solution 1)
Avec int√©gration progressive vers **Hybrid Selector** (Solution 3)

### Roadmap d'impl√©mentation

#### Phase 1 : Quick Win (Semaine 1)
1. **D√©sactiver l'auto-calibration** dans ExponentialSmoothingPlugin
   - Lignes 154-162 √† commenter/supprimer
   - Risque inacceptable de masquer les hypers

2. **Cr√©er AdaptiveSmoothingPlugin**
   - Impl√©mentation compl√®te avec les 4 modes
   - Tests unitaires avec vos donn√©es du matin

3. **A/B Testing**
   - Journ√©e 1-3 : Avg
   - Journ√©e 4-6 : Adaptive
   - Comparer : Time in Range, SD, lag observ√©

#### Phase 2 : Optimisation (Semaine 2)
1. **Tuning des seuils**
   - Ajuster les seuils de delta/CV selon vos r√©sultats
   - Int√©gration des learners AIMI (UnifiedReactivity, PKPD)

2. **Logging avanc√©**
   - Tracer mode s√©lectionn√©, √©cart raw/smoothed
   - Dashboard de diagnostic

#### Phase 3 : Evolution (Semaine 3-4)
1. **Hybrid Selector**
   - Auto-s√©lection entre No/Avg/Exp/Adaptive
   - Logs de d√©cision pour analyse

2. **ML Tuning** (optionnel)
   - Entra√Æner un mod√®le √† s√©lectionner les param√®tres optimaux
   - Input : BG, IOB, COB, historique
   - Output : Poids de lissage optimaux

---

## üß™ PROCHAINES √âTAPES CONCR√àTES

### 1. Validation rapide (aujourd'hui)
```bash
# D√©sactiver auto-calibration dangereuse
git checkout -b fix/remove-dangerous-autocal
# Modifier ExponentialSmoothingPlugin.kt
# Commit + test
```

### 2. POC Adaptive (cette semaine)
```bash
git checkout -b feature/adaptive-smoothing
# Cr√©er AdaptiveSmoothingPlugin.kt
# Impl√©menter les 4 modes
# Tests avec vos donn√©es
```

### 3. Validation terrain (semaine prochaine)
- Activer Adaptive en production
- Logger les √©carts raw/smoothed
- Comparer TIR, variabilit√©, pic glyc√©miques

---

## üí¨ Questions ouvertes pour affiner

1. **Pr√©f√©rences de s√©curit√©** : Faut-il d√©sactiver TOUT lissage en dessous de 70 mg/dL ?

2. **Int√©gration PKPD** : Le contexte IOB/COB doit-il moduler le lissage ?

3. **Capteur** : Y a-t-il des patterns sp√©cifiques au Dexcom One+ √† exploiter ?

4. **Historique** : Avez-vous des logs d√©taill√©s d'autres situations de 30 mg/dL d'√©cart ?

---

## üèÜ B√âN√âFICES ATTENDUS

Avec **Adaptive Smoothing** :
- ‚úÖ R√©duction du lag : **10 min ‚Üí 2-4 min**
- ‚úÖ √âcart max raw/smoothed : **30 mg/dL ‚Üí 7-10 mg/dL**
- ‚úÖ Time in Range : **+5-8%**
- ‚úÖ Pics post-prandiaux : **-15-20 mg/dL**
- ‚úÖ S√©curit√© hypo : **Maintenue** (mode asym√©trique)

---

**Lyra, pr√™t √† impl√©menter. Quelle phase voulez-vous lancer en priorit√© ?** üöÄ
